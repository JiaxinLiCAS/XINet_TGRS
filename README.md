# XINet_TGRS
X-Shaped Interactive Autoencoders With Cross-Modality Mutual Learning for Unsupervised Hyperspectral Image Super-Resolution, TGRS. (PyTorch)
<!--
[Jiaxin Li æå˜‰é‘«](https://www.researchgate.net/profile/Li-Jiaxin-20), [Ke Zheng éƒ‘ç‚](https://www.researchgate.net/profile/Ke-Zheng-9), [Zhi Li ææ™º](https://ieeexplore.ieee.org/author/37085683916),  [Lianru Gao é«˜è¿å¦‚](https://scholar.google.com/citations?hl=en&user=f6OnhtcAAAAJ), and [Xiuping Jia è´¾ç§€è](https://scholar.google.com/citations?user=-vl0ZSEAAAAJ&hl=zh-CN)ï¼ŒIEEE Transactions on Geoscience and Remote Sensing (TGRS). 

æ–‡ç« å¯åœ¨è¿™é‡Œä¸‹è½½ğŸ–¼ï¸[**PDF**](./Imgs/XINet.pdf)ï¼ŒThe final version can be downloaded in  ğŸ–¼ï¸[**PDF**](./Imgs/XINet.pdf) 


# $\color{red}{æ¬¢è¿æ·»åŠ  æˆ‘çš„å¾®ä¿¡(WeChat): BatAugï¼Œæ¬¢è¿äº¤æµä¸åˆä½œ}$

## æœ¬äººè¿˜æå‡ºäº†å…¶ä½™å¤šä¸ªå¼€æºçš„é«˜å…‰è°±-å¤šå…‰è°±è¶…åˆ†èåˆä»£ç ï¼Œå¯ç§»æ­¥è‡³[GitHubä¸»é¡µä¸‹è½½](https://github.com/JiaxinLiCAS) 


### æˆ‘æ˜¯æå˜‰é‘«ï¼Œ25å¹´æ¯•ä¸šäºä¸­ç§‘é™¢ç©ºå¤©ä¿¡æ¯åˆ›æ–°ç ”ç©¶é™¢çš„ç›´åšç”Ÿï¼Œå¯¼å¸ˆé«˜è¿å¦‚ç ”ç©¶å‘˜ ###

æˆ‘çš„è‹±æ–‡ç‰ˆæœ¬ä¸ªäººç®€å†å¯åœ¨éš”å£ä»“åº“ä¸‹è½½ï¼Œå¦‚æ‚¨éœ€è¦æ­¤ç®€å†æ¨¡æ¿å¯ä»¥é€šè¿‡å¾®ä¿¡è”ç³»æˆ‘ã€‚
My english CV can be downloaded in this repository [![Static Badge](https://img.shields.io/badge/PDF-Download-blue])](https://github.com/JiaxinLiCAS/My-Curriculum-Vitae-CV-/blob/main/CV_JiaxinLi.pdf).

2025.09â€”â€”, å°±èŒäºé‡åº†é‚®ç”µå¤§å­¦ è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢ æ–‡å³°å‰¯æ•™æˆ $\color{red}{åšåå¯¼å¸ˆï¼šéŸ©å†›ä¼Ÿæ•™æˆ}$ 
ã€[å®˜ç½‘](https://teacher.nwpu.edu.cn/hanjunwei.html)ï¼Œ[è°·æ­Œå­¦æœ¯ä¸»é¡µ](https://scholar.google.com/citations?user=xrqsoesAAAAJ&hl=zh-CN&oi=ao)ã€‘

2020.09-2025.07 å°±è¯»äºä¸­å›½ç§‘å­¦é™¢ ç©ºå¤©ä¿¡æ¯åˆ›æ–°ç ”ç©¶é™¢ äº”å¹´åˆ¶ç›´åšç”Ÿ $\color{red}{å¯¼å¸ˆï¼šé«˜è¿å¦‚ç ”ç©¶å‘˜}$ ã€[å¯¼å¸ˆç©ºå¤©é™¢å®˜ç½‘](https://people.ucas.ac.cn/~gaolianru)ï¼Œ[è°·æ­Œå­¦æœ¯ä¸»é¡µ](https://scholar.google.com/citations?user=La-8gLMAAAAJ&hl=zh-CN)ã€‘

2016.09-2020.7 å°±è¯»äºé‡åº†å¤§å­¦ åœŸæœ¨å·¥ç¨‹å­¦é™¢ æµ‹ç»˜å·¥ç¨‹ä¸“ä¸š

From 2025.09, I work at the School of Computer Science and Technology (National Exemplary Software School), Chongqing University of Posts and Telecommunications, as a Wenfeng associate professor.
My postdoctoral supervisor is [Junwei Han](https://scholar.google.com/citations?user=La-8gLMAAAAJ&hl=zh-CN).

From 2020.09 to 2025.07, I am a PhD candidate at the Key Laboratory of Computational Optical Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China.
My supervisor is [Lianru Gao](https://scholar.google.com/citations?user=La-8gLMAAAAJ&hl=zh-CN).

From 2016.0 to 2020.7, I studied in the school of civil engineering at Chongqing University, Chongqing, China, for a Bachelor of Engineering.

è¿™æ˜¯æˆ‘çš„[è°·æ­Œå­¦æœ¯](https://scholar.google.com/citations?user=aSPDpmgAAAAJ&hl=zh-CN)å’Œ[ResearchGate](https://www.researchgate.net/profile/Jiaxin-Li-lijiaxin?ev=hdr_xprf)ï¼ŒMore information can be found in my [Google Scholar Citations](https://scholar.google.com/citations?user=aSPDpmgAAAAJ&hl=zh-CN) and my [ResearchGate](https://www.researchgate.net/profile/Jiaxin-Li-lijiaxin?ev=hdr_xprf)
-->

# ä»£ç è§£æ ğŸ‘‡ æœ‰åŠ©ä½ è¯»æ‡‚ä»£ç  ä¾¿äºå¤ç°

ğŸ–¼ï¸**é‡åˆ°ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºä»£ç è°ƒè¯•ã€æ•°æ®ä»¿çœŸã€è¿è¡Œç»“æœç­‰ï¼Œéšæ—¶æ·»åŠ **
$\color{red}{æˆ‘çš„å¾®ä¿¡(WeChat): BatAugï¼Œæ¬¢è¿äº¤æµä¸åˆä½œ}$

<img src="./Imgs/fig1.png" width="666px"/>

**Fig.1.** Overall Pipeline of proposed method, abbreviated as XINet, for the task of unsupervised hyperspectral image super-resolution.

## æ–‡ä»¶ç»“æ„ Directory structure
<img src="./Imgs/fig2.png" width="200px"/>

**Fig.2.** Directory structure. There are four folders and one main.py file in XINet_TGRS-main.

### checkpoints
è¿™ä¸ªæ–‡ä»¶å¤¹ç”¨äºå‚¨å­˜è®­ç»ƒä¸­çš„æ‰€æœ‰ç»“æœï¼Œè¿™é‡Œç»™å‡ºäº†TGæ•°æ®çš„ç¤ºä¾‹ã€‚å¦‚æœä½ ç›´æ¥è¿è¡Œmain.py,å°†ä¼šåœ¨`TG_SF12_endnum130_fl0.8_blo3_A100_B100_C10_E0.01__use_ATV1_CMMIYes_blindYes`æ–‡ä»¶å¤¹ä¸­ç”Ÿæˆä»¥ä¸‹çš„è¿™äº›æ–‡ä»¶

This folder is used to store the results and a folder named `TG_SF12_endnum130_fl0.8_blo3_A100_B100_C10_E0.01__use_ATV1_CMMIYes_blindYes` is given as an example.

- `BlindNet.pth` is the trained parameters of the degradation model. å› ä¸ºæœ¬æ–¹æ³•æ˜¯ç›²èåˆï¼Œå› æ­¤éœ€è¦ä¼°è®¡æœªçŸ¥çš„PSFå’ŒSRF

- `estimated_psf_srf.mat` is the estimated PSF and SRF. ä¼°è®¡åˆ°çš„PSFå’ŒSRF

- `hr_msi.mat` and `lr_hsi.mat`  are simulated results as the input of our method. ç”±è¾“å…¥çš„TGæ•°æ®ä»¿çœŸå¾—åˆ°çš„LrHSIå’ŒHrMSI

- `opt.txt` is the configuration of our method. å­˜å‚¨æœ¬æ¬¡å®éªŒçš„æ‰€æœ‰é…ç½®ï¼ŒåŒ…æ‹¬è¶…å‚æ•°ä»¥åŠæ•°æ®åç§°ç­‰ï¼Œç”±modelé‡Œçš„config.pyå†³å®š

- `psf_gt.mat` and  `srf_gt.mat` are the GT PSF and SRF. PSF å’Œ SRFçš„çœŸå€¼

- `Out.mat` is the final estimation. æœ¬æ–¹æ³•æœ€ç»ˆé‡å»ºç»“æœ

- `loss_log.txt` is the training loss in the training process. è®°å½•è®­ç»ƒè¿‡ç¨‹çš„æŸå¤±å˜åŒ–

- `precision.txt` is the training accuracy in the training process. è®°å½•è®­ç»ƒè¿‡ç¨‹çš„ç²¾åº¦å˜åŒ–
  
- `psnr_and_sam.pickle` is the psnr and sam accuracy in the training process. ä¿å­˜è®­ç»ƒè¿‡ç¨‹çš„PSNR å’Œ SAM
  
### data
This folder is used to store the ground true HSI and corresponding spectral response of multispectral imager, aiming to generate the simulated inputs. The TianGong-1 HSI data and spectral response of WorldView 2 multispectral imager are given as an example here.

è¿™é‡Œç»™å‡ºäº†ä¸€ä¸ªç¤ºä¾‹ã€‚XINetæ–‡ä»¶é‡Œçš„TGæ–‡ä»¶å¤¹æ˜¯TGæ•°æ®çš„çœŸå€¼ï¼Œspectral_responseæ˜¯ç”¨æ¥ä»¿çœŸHrMSIçš„å…‰è°±å“åº”å‡½æ•°ã€‚

### model
This folder consists of six .py files, including 
- `__init__.py`

- `config.py`: all the hyper-parameters can be adjusted here. æœ¬æ–¹æ³•æ‰€æœ‰éœ€è¦è°ƒæ•´çš„å‚æ•°ï¼ŒåŒ…å«æ•°æ®è¯»å–åœ°å€ä»¥åŠæ¨¡å‹è¶…å‚æ•°ç­‰

- `evaluation.py`: to evaluate the metrics. è¯„ä»·æŒ‡æ ‡è®¡ç®—

- `network.py`: the network used in our model. æœ¬æ–¹æ³•ä½¿ç”¨åˆ°çš„ç½‘ç»œæ¨¡å—

- `read_data.py`: read and simulate data. è¯»å–æ•°æ®å’Œä»¿çœŸæ•°æ®

- `fusion.py`: XINet. é‡å»ºèåˆä¸»ç½‘ç»œ

- `srf_psf_layer.py`: the network to estimate PSF and SRF. ç”¨äºä¼°è®¡PSFå’ŒSRFï¼Œä½œä¸ºXINetçš„è¾“å…¥

### utils
This folder consists of four .py files, including 
- `__init__.py`

- `evaluation.py`: to evaluate the metrics. è¯„ä»·æŒ‡æ ‡è®¡ç®—

- `util.py`: some tools. ä¸€äº›å·¥å…·å‡½æ•°

- â—`visualizer.py`: to display the training results. **ç”¨äºå¯è§†åŒ–è®­ç»ƒä¸­çš„ç»“æœï¼ŒåŸºäºVisdomå¯è§†åŒ–åŒ…**  

### main
- `main.py`: main.py è¿è¡Œè¯¥æ–‡ä»¶ï¼Œç”Ÿæˆç›®æ ‡å›¾åƒ

## å¦‚ä½•è¿è¡Œæˆ‘ä»¬çš„ä»£ç  How to run our code
1. Requirements: codes of networks were tested using PyTorch 1.9.0 version (CUDA 11.4) in Python 3.8.10 on Windows system.

2. Parameters: all the parameters need fine-tunning can be found in `config.py`. æœ¬æ–¹æ³•æ‰€æœ‰éœ€è¦è°ƒæ•´çš„å‚æ•°éƒ½åœ¨æ­¤.pyä¸­

3. Data: put your HSI data and MSI spectral response in `./data/XINet/TG` and `./data/XINet/spectral_response`, respectively. The TianGong-1 HSI data and spectral response of WorldView 2 multispectral imager are given as an example here.

  å°†ä½ çš„é«˜å…‰è°±æ•°æ®ä»¥åŠç”¨äºä»¿çœŸHrMSIçš„å…‰è°±å“åº”æ”¾åˆ°å¯¹åº”æ–‡ä»¶å¤¹ä¸­ï¼Œè¿™é‡Œç”¨TGæ•°æ®ä½œä¸ºç¤ºä¾‹

4. You should download the Visdom via pip or conda, and then type 'visdom -port 8500' into the terminal (the number should be identical to the --display_port in the model/config.py. Last, you can enter the site(http://localhost:8500/) the terminal give to you)

  **å› ä¸ºæœ¬æ–¹æ³•ä½¿ç”¨äº†Visdomå¯è§†åŒ–åŒ…å®ç°å¯¹è®­ç»ƒè¿‡ç¨‹çš„å¯è§†åŒ–ï¼Œå› æ­¤VidsomåŒ…çš„å®‰è£…æ˜¯å¿…å¤‡è¿‡ç¨‹ã€‚ä»¥ä¸‹å°†ç®€å•ä»‹ç»VisdomåŒ…çš„å®‰è£…å’Œä½¿ç”¨ï¼š**

  4.1 åœ¨ä½ æ‰€åœ¨ç¯å¢ƒä¸­ ä½¿ç”¨ conda/pip install visdomï¼Œå®Œæˆå¯¹å·¥å…·åŒ…çš„å®‰è£…ã€‚å…·ä½“è¿‡ç¨‹å¯è§[æ­¤](https://cloud.tencent.com/developer/article/2053918)
  
  4.2 å®‰è£…æˆåŠŸåï¼ŒåŒæ—¶æŒ‰ä¸‹WIN+Rï¼Œè¾“å…¥CMDè¿›å…¥ç»ˆç«¯ï¼Œåœ¨ä½ æ‰€åœ¨ç¯å¢ƒçš„ç»ˆç«¯é‡Œè¾“å…¥ visdom -port 8500 **ï¼ˆæ³¨æ„ï¼šåé¢çš„æ•°å­—å¯ä»¥éšæ„ï¼Œä½†éœ€è¦è·Ÿmodel/config.pyé‡Œé¢çš„--display_portå‚æ•°ä¿æŒä¸€è‡´)** ã€‚

  æ­¤æ—¶ï¼Œç»ˆç«¯ä¼šæç¤ºä½ è¿›å…¥ http://localhost:8500/ ç½‘å€ï¼Œå¤åˆ¶è¯¥åœ°å€è¿›å…¥æµè§ˆå™¨ã€‚è¿™ä¸ªç½‘ç«™åç»­å°±ä¼šå¯è§†åŒ–è®­ç»ƒçš„è¿‡ç¨‹ã€‚

  æ›´å¤šå…³äºVisdomå¯è§†åŒ–æ–¹æ³•å¯è§[æ­¤](https://blog.csdn.net/2401_88244350/article/details/143364300)
  
5. Run: just simply run `main.py` after adjusting the parameters in `config.py`.
  åœ¨å¯¹åº”æ–‡ä»¶å¤¹æ”¾ç½®ä½ çš„æ•°æ®åï¼Œè°ƒæ•´ `config.py`åçš„å‚æ•°ï¼Œå³å¯è¿è¡Œ`main.py`

  **å½“ä½ è§‰å¾—æ•ˆæœæ¬ ä½³æ—¶ï¼Œå¯ä»¥è°ƒæ•´é‡Œé¢çš„ -endmember_num ä¸ªæ•°ã€‚**
   
7. Results: one folder named `TG_SF12_endnum130_fl0.8_blo3_A100_B100_C10_E0.01__use_ATV1_CMMIYes_blindYes` will be generated once `main.py` is run and all the results will be stored in the new folder. Also, you can observe the training process in the above-opened site via Visdom.
  å½“ä½ è¿è¡Œæœ¬ä»£ç åï¼Œå°†ä¼šç”Ÿæˆ`TG_SF12_endnum130_fl0.8_blo3_A100_B100_C10_E0.01__use_ATV1_CMMIYes_blindYes` æ–‡ä»¶å¤¹ï¼Œé‡Œé¢å­˜å‚¨æ‰€æœ‰ç»“æœ.

  åŒæ—¶ï¼Œä½ å¯ä»¥åœ¨åˆšæ‰æ‰“å¼€çš„ç½‘ç«™é‡Œå®æ—¶ç›‘æ§æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹,å¦‚ä¸‹å›¾æ‰€è§.

  6.1 å·¦ä¸Šè§’ä»£è¡¨æ¯ä¸ªæŸå¤±éšç€è®­ç»ƒçš„å˜åŒ–è¿‡ç¨‹ã€‚å·¦ä¸‹è§’åˆ†åˆ«æ˜¯å­¦ä¹ ç‡çš„å˜åŒ–ä»¥åŠPSNR-SAMçš„å˜åŒ–ã€‚
  
  6.2 ä¸­é—´å¯è§†åŒ–6å¼ å›¾ã€‚ç¬¬ä¸€åˆ—åˆ†åˆ«æ˜¯LrHSI HrMSI HrHSIçœŸå€¼ï¼Œå³ä¾§åˆ†åˆ«ä»£è¡¨è‡ªç¼–ç å™¨é‡å»ºå‡ºæ¥çš„ç»“æœ

  
  **æ³¨æ„ï¼šå½“ä½ å‘ç°ç¬¬äºŒåˆ—ä¸€ç›´ä¸ºé»‘è‰²ï¼Œå¯ä»¥ä¸­æ–­ç¨‹åºï¼Œæ¢ä¸€ä¸ªéšæœºç§å­å†æ¬¡è¿è¡Œ**
  
  6.3 å³ä¾§ä¸¤å¼ å›¾ã€‚ä¸Šæ–¹lrhsiçœŸå€¼ä»¥åŠè‡ªç¼–ç é‡å»ºå‡ºæ¥çš„lrhsiåœ¨ç›¸åŒä½ç½®çš„å…‰è°±æ›²çº¿ï¼Œä¸‹æ–¹ä»£è¡¨HrHSIä»¥åŠé‡å»ºHrHSIåœ¨ç›¸åŒä½ç½®çš„å…‰è°±æ›²çº¿ã€‚æ³¨æ„ï¼šåœ¨æ¯è½®å¯è§†åŒ–çš„æ—¶å€™ï¼Œé€‰å–çš„åƒç´ ä½ç½®éƒ½ä¼šå˜åŒ–ã€‚


<img src="./Imgs/fig3.png" width="2000px"/>

**Fig.3.** Visdom visualization.

## å¦‚ä½•è”ç³»æˆ‘ä»¬ Contact
é‡åˆ°ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºä»£ç è°ƒè¯•ã€æ•°æ®ä»¿çœŸã€è¿è¡Œç»“æœç­‰ï¼Œéšæ—¶æ·»åŠ 
$\color{red}{æˆ‘çš„å¾®ä¿¡(WeChat): BatAugï¼Œæ¬¢è¿äº¤æµä¸åˆä½œ}$

If you encounter any bugs while using this code, please do not hesitate to contact us. lijiaxin203@mails.ucas.ac.cn


