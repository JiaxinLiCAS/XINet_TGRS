# XINet
X-Shaped Interactive Autoencoders With Cross-Modality Mutual Learning for Unsupervised Hyperspectral Image Super-Resolution, TGRS. (PyTorch)

# $\color{red}{æ¬¢è¿æ·»åŠ  æˆ‘çš„å¾®ä¿¡(WeChat): BatAugï¼Œæ¬¢è¿äº¤æµä¸åˆä½œ}$

## æœ¬äººè¿˜æå‡ºäº†å…¶ä½™å¤šä¸ªå¼€æºçš„é«˜å…‰è°±-å¤šå…‰è°±è¶…åˆ†èåˆä»£ç ï¼Œå¯ç§»æ­¥è‡³[GitHubä¸»é¡µä¸‹è½½](https://github.com/JiaxinLiCAS) 

[Jiaxin Li](https://www.researchgate.net/profile/Li-Jiaxin-20), [Ke Zheng](https://www.researchgate.net/profile/Ke-Zheng-9), [Zhi Li](https://ieeexplore.ieee.org/author/37085683916),  [Lianru Gao](https://scholar.google.com/citations?hl=en&user=f6OnhtcAAAAJ), and [Xiuping Jia](https://scholar.google.com/citations?user=-vl0ZSEAAAAJ&hl=zh-CN)

Our paper is accepted by IEEE Transactions on Geoscience and Remote Sensing (TGRS). 

æ–‡ç« å¯åœ¨è¿™é‡Œä¸‹è½½ğŸ–¼ï¸[**PDF**](./Imgs/XINet.pdf)ï¼ŒThe final version can be downloaded in  ğŸ–¼ï¸[**PDF**](./Imgs/XINet.pdf) 


è¿™æ˜¯æˆ‘çš„[è°·æ­Œå­¦æœ¯](https://scholar.google.com/citations?user=aSPDpmgAAAAJ&hl=zh-CN)å’Œ[ResearchGate](https://www.researchgate.net/profile/Jiaxin-Li-lijiaxin?ev=hdr_xprf)ï¼ŒMore information can be found in my [Google Scholar Citations](https://scholar.google.com/citations?user=aSPDpmgAAAAJ&hl=zh-CN) and my [ResearchGate](https://www.researchgate.net/profile/Jiaxin-Li-lijiaxin?ev=hdr_xprf)

<img src="./Imgs/fig1.png" width="666px"/>

**Fig.1.** Overall Pipeline of proposed method, abbreviated as XINet, for the task of unsupervised hyperspectral image super-resolution.

## æ–‡ä»¶ç»“æ„ Directory structure
<img src="./Imgs/fig2.png" width="200px"/>

**Fig.2.** Directory structure. There are four folders and one main.py file in XINet_TGRS-main.

### checkpoints
è¿™ä¸ªæ–‡ä»¶å¤¹ç”¨äºå‚¨å­˜è®­ç»ƒä¸­çš„æ‰€æœ‰ç»“æœï¼Œè¿™é‡Œç»™å‡ºäº†TGæ•°æ®çš„ç¤ºä¾‹ã€‚å¦‚æœä½ ç›´æ¥è¿è¡Œmain.py,å°†ä¼šåœ¨`TG_SF12_endnum130_fl0.8_blo3_A100_B100_C10_E0.01__use_ATV1_CMMIYes_blindYes`æ–‡ä»¶å¤¹ä¸­ç”Ÿæˆä»¥ä¸‹çš„è¿™äº›æ–‡ä»¶

This folder is used to store the results and a folder named `TGSF12_band240_S1_0.001_2000_2000_S2_0.004_2000_2000_S3_0.004_7000_7000` is given as an example.

- `BlindNet.pth` is the trained parameters of Stage One. ç¬¬ä¸€é˜¶æ®µç½‘ç»œè®­ç»ƒå¥½çš„å‚æ•°

- `estimated_lr_msi.mat` is the estimated LrMSI in Stage One. ç¬¬ä¸€é˜¶æ®µä¼°è®¡åˆ°çš„LrMSI

- `estimated_psf_srf.mat` is the estimated PSF and SRF. ç¬¬ä¸€é˜¶æ®µä¼°è®¡åˆ°çš„PSFå’ŒSRF

- `gt_lr_msi.mat` is the gt lr_msi. LrMSIçš„çœŸå€¼

- `hr_msi.mat` and `lr_hsi.mat`  are simulated results as the input of our method. ç”±è¾“å…¥çš„TGæ•°æ®ä»¿çœŸå¾—åˆ°çš„LrHSIå’ŒHrMSI

- `opt.txt` is the configuration of our method. å­˜å‚¨æœ¬æ¬¡å®éªŒçš„æ‰€æœ‰é…ç½®ï¼ŒåŒ…æ‹¬è¶…å‚æ•°ä»¥åŠæ•°æ®åç§°ç­‰ï¼Œç”±modelé‡Œçš„config.pyå†³å®š
  
- `Out_fhsi_S2.mat` and `Out_fhsi_S3.mat` is the estimated HrHSI from S2 and S3 in the stream of lrhsi. ç”±hsiåˆ†æ”¯åœ¨ç¬¬äºŒå’Œç¬¬ä¸‰é˜¶æ®µç”Ÿæˆçš„HrHSIä¼°è®¡ç»“æœ

- `Out_fmsi_S2.mat` and `Out_fmsi_S3.mat` is the estimated HrHSI from S2 and S3 in the stream of hrmsi. ç”±msiåˆ†æ”¯åœ¨ç¬¬äºŒå’Œç¬¬ä¸‰é˜¶æ®µç”Ÿæˆçš„HrHSIä¼°è®¡ç»“æœ

- `psf_gt.mat` and  `srf_gt.mat` are the GT PSF and SRF. PSF å’Œ SRFçš„çœŸå€¼

- `srf_Out_S4.mat` is the final estimation of our method. æœ¬æ–¹æ³•æœ€ç»ˆä¼°è®¡çš„ç»“æœ

- `Stage1.txt` is the training accuracy of Stage One.ç¬¬1é˜¶æ®µçš„ç²¾åº¦

- `Stage2.txt` is the training accuracy of Stage Two.ç¬¬2é˜¶æ®µçš„ç²¾åº¦
  
- `Stage3.txt` is the training accuracy of Stage Three.ç¬¬3é˜¶æ®µçš„ç²¾åº¦

- `Stage4.txt` is the training accuracy of Stage Four.ç¬¬4é˜¶æ®µçš„ç²¾åº¦
  
### data
This folder is used to store the ground true HSI and corresponding spectral response of multispectral imager, aiming to generate the simulated inputs. The TianGong-1 HSI data and spectral response of WorldView 2 multispectral imager are given as an example here.

è¿™é‡Œç»™å‡ºäº†ä¸€ä¸ªç¤ºä¾‹ã€‚EDIP-Netæ–‡ä»¶é‡Œçš„TGæ–‡ä»¶å¤¹æ˜¯TGæ•°æ®çš„çœŸå€¼ï¼Œspectral_responseæ˜¯ç”¨æ¥ä»¿çœŸHrMSIçš„å…‰è°±å“åº”å‡½æ•°ã€‚

### model
This folder consists of ten .py files, including 
- `__init__.py`

- `config.py`: all the hyper-parameters can be adjusted here. æœ¬æ–¹æ³•æ‰€æœ‰éœ€è¦è°ƒæ•´çš„å‚æ•°ï¼ŒåŒ…å«æ•°æ®è¯»å–åœ°å€ä»¥åŠæ¨¡å‹è¶…å‚æ•°ç­‰

- `dip.py`: the stage three. å¯¹åº”ç¬¬ä¸‰é˜¶æ®µ

- `evaluation.py`: to evaluate the metrics. è¯„ä»·æŒ‡æ ‡è®¡ç®—

- `network_s2.py`: the network used in the Stage Two. é˜¶æ®µäºŒæ‰€éœ€è¦çš„ç½‘ç»œæ¨¡å‹

- `network_s3.py`: the network used in the Stage Three. é˜¶æ®µä¸‰æ‰€éœ€è¦çš„ç½‘ç»œæ¨¡å‹

- `read_data.py`: read and simulate data. è¯»å–æ•°æ®å’Œä»¿çœŸæ•°æ®

- `select.py`: generate the final result from Stage three. å¯¹é˜¶æ®µä¸‰çš„ä¸¤ä¸ªè¾“å‡ºè¿›è¡Œèåˆ

- `spectral_up.py`: the network in the Stage Two. å¯¹åº”é˜¶æ®µäºŒ

- `srf_psf_layer.py`: the network in the Stage One. å¯¹åº”é˜¶æ®µä¸€

### main
- `main.py`: main.py è¿è¡Œè¯¥æ–‡ä»¶ï¼Œç”Ÿæˆç›®æ ‡å›¾åƒ

## å¦‚ä½•è¿è¡Œæˆ‘ä»¬çš„ä»£ç  How to run our code
- Requirements: codes of networks were tested using PyTorch 1.9.0 version (CUDA 11.4) in Python 3.8.10 on Windows system.

- Parameters: all the parameters need fine-tunning can be found in `config.py`. æœ¬æ–¹æ³•æ‰€æœ‰éœ€è¦è°ƒæ•´çš„å‚æ•°éƒ½åœ¨æ­¤.pyä¸­

- Data: put your HSI data and MSI spectral reponse in `./data/EDIP-Net/TG` and `./data/EDIP-Net/spectral_response`, respectively. The TianGong-1 HSI data and spectral response of WorldView 2 multispectral imager are given as an example here.

  å°†ä½ çš„é«˜å…‰è°±æ•°æ®ä»¥åŠç”¨äºä»¿çœŸHrMSIçš„å…‰è°±å“åº”æ”¾åˆ°å¯¹åº”æ–‡ä»¶å¤¹ä¸­ï¼Œè¿™é‡Œç”¨TGæ•°æ®ä½œä¸ºç¤ºä¾‹

- Run: just simply run `main.py` after adjusting the parameters in `config.py`.
  åœ¨å¯¹åº”æ–‡ä»¶å¤¹æ”¾ç½®ä½ çš„æ•°æ®åï¼Œè°ƒæ•´ `config.py`åçš„å‚æ•°ï¼Œå³å¯è¿è¡Œ`main.py`

- Results: one folder named `TGSF12_band260_S1_0.001_3000_3000_S2_0.004_2000_2000_S3_0.004_7000_7000` will be generated once `main.py` is run and all the results will be stored in the new folder.
  å½“ä½ è¿è¡Œæœ¬ä»£ç åï¼Œå°†ä¼šç”Ÿæˆ` TGSF12_band260_S1_0.001_3000_3000_S2_0.004_2000_2000_S3_0.004_7000_7000` æ–‡ä»¶å¤¹ï¼Œé‡Œé¢å­˜å‚¨æ‰€æœ‰ç»“æœ


## å¦‚ä½•è”ç³»æˆ‘ä»¬ Contact
é‡åˆ°ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºä»£ç è°ƒè¯•ã€æ•°æ®ä»¿çœŸã€è¿è¡Œç»“æœç­‰ï¼Œéšæ—¶æ·»åŠ 
$\color{red}{æˆ‘çš„å¾®ä¿¡(WeChat): BatAugï¼Œæ¬¢è¿äº¤æµä¸åˆä½œ}$

If you encounter any bugs while using this code, please do not hesitate to contact us. lijiaxin203@mails.ucas.ac.cn


